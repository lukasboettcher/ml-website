import { IMAGE_H, IMAGE_W, Data } from '../../mnist/tutorial/data';
import * as tf from '@tensorflow/tfjs';

export class ACGAN {
    // Number of classes in the MNIST dataset.
    numClasses = 10;

    // MNIST image size.
    imageSize = 28;

    // "Soft" one used for training the combined ACGAN model.
    // This is an important trick in training GANs.
    softOne = 0.95;

    mnistData: Data;


    buildGenerator(latentSize) {

        const cnn = tf.sequential();

        // The number of units is chosen so that when the output is reshaped
        // and fed through the subsequent conv2dTranspose layers, the tensor
        // that comes out at the end has the exact shape that matches MNIST
        // images ([28, 28, 1]).
        cnn.add(tf.layers.dense(
            { units: 3 * 3 * 384, inputShape: [latentSize], activation: 'relu' }));
        cnn.add(tf.layers.reshape({ targetShape: [3, 3, 384] }));

        // Upsample from [3, 3, ...] to [7, 7, ...].
        cnn.add(tf.layers.conv2dTranspose({
            filters: 192,
            kernelSize: 5,
            strides: 1,
            padding: 'valid',
            activation: 'relu',
            kernelInitializer: 'glorotNormal'
        }));
        cnn.add(tf.layers.batchNormalization());

        // Upsample to [14, 14, ...].
        cnn.add(tf.layers.conv2dTranspose({
            filters: 96,
            kernelSize: 5,
            strides: 2,
            padding: 'same',
            activation: 'relu',
            kernelInitializer: 'glorotNormal'
        }));
        cnn.add(tf.layers.batchNormalization());

        // Upsample to [28, 28, ...].
        cnn.add(tf.layers.conv2dTranspose({
            filters: 1,
            kernelSize: 5,
            strides: 2,
            padding: 'same',
            activation: 'tanh',
            kernelInitializer: 'glorotNormal'
        }));

        // Unlike most TensorFlow.js models, the generator part of an ACGAN has
        // two inputs:
        //   1. The latent vector that is used as the "seed" of the fake image
        //      generation.
        //   2. A class label that controls which of the ten MNIST digit classes
        //      the generated fake image is meant to belong to.

        // This is the z space commonly referred to in GAN papers.
        const latent = tf.input({ shape: [latentSize] });

        // The desired label of the generated image, an integer in the interval
        // [0, numClasses).
        const imageClass = tf.input({ shape: [1] });

        // The desired label is converted to a vector of length `latentSize`
        // through embedding lookup.
        const classEmbedding = tf.layers.embedding({
            inputDim: this.numClasses,
            outputDim: latentSize,
            embeddingsInitializer: 'glorotNormal'
        }).apply(imageClass) as tf.SymbolicTensor;

        // Hadamard product between z-space and a class conditional embedding.
        const h = tf.layers.multiply().apply([latent, classEmbedding]);
        // const h = tf.layers.multiply().apply([classEmbedding]);

        const fakeImage = cnn.apply(h) as tf.SymbolicTensor;
        return tf.model({ inputs: [latent, imageClass], outputs: fakeImage });
    }

    buildDiscriminator() {
        const cnn = tf.sequential();

        cnn.add(tf.layers.conv2d({
            filters: 32,
            kernelSize: 3,
            padding: 'same',
            strides: 2,
            inputShape: [this.imageSize, this.imageSize, 1]
        }));
        cnn.add(tf.layers.leakyReLU({ alpha: 0.2 }));
        cnn.add(tf.layers.dropout({ rate: 0.3 }));

        cnn.add(tf.layers.conv2d(
            { filters: 64, kernelSize: 3, padding: 'same', strides: 1 }));
        cnn.add(tf.layers.leakyReLU({ alpha: 0.2 }));
        cnn.add(tf.layers.dropout({ rate: 0.3 }));

        cnn.add(tf.layers.conv2d(
            { filters: 128, kernelSize: 3, padding: 'same', strides: 2 }));
        cnn.add(tf.layers.leakyReLU({ alpha: 0.2 }));
        cnn.add(tf.layers.dropout({ rate: 0.3 }));

        cnn.add(tf.layers.conv2d(
            { filters: 256, kernelSize: 3, padding: 'same', strides: 1 }));
        cnn.add(tf.layers.leakyReLU({ alpha: 0.2 }));
        cnn.add(tf.layers.dropout({ rate: 0.3 }));

        cnn.add(tf.layers.flatten());

        const image = tf.input({ shape: [this.imageSize, this.imageSize, 1] });
        const features = cnn.apply(image);

        // Unlike most TensorFlow.js models, the discriminator has two outputs.

        // The 1st output is the probability score assigned by the discriminator to
        // how likely the input example is a real MNIST image (as versus
        // a "fake" one generated by the generator).
        const realnessScore =
            tf.layers.dense({ units: 1, activation: 'sigmoid' }).apply(features) as tf.SymbolicTensor;
        // The 2nd output is the softmax probabilities assign by the discriminator
        // for the 10 MNIST digit classes (0 through 9). "aux" stands for "auxiliary"
        // (the namesake of ACGAN) and refers to the fact that unlike a standard GAN
        // (which performs just binary real/fake classification), the discriminator
        // part of ACGAN also performs multi-class classification.
        const aux = tf.layers.dense({ units: this.numClasses, activation: 'softmax' })
            .apply(features) as tf.SymbolicTensor;

        return tf.model({ inputs: image, outputs: [realnessScore, aux] });
    }

    buildCombinedModel(latentSize, generator, discriminator, optimizer) {
        // Latent vector. This is one of the two inputs to the generator.
        const latent = tf.input({ shape: [latentSize] });
        // Desired image class. This is the second input to the generator.
        const imageClass = tf.input({ shape: [1] });
        // Get the symbolic tensor for fake images generated by the generator.
        const fakeTmp = generator.apply([latent, imageClass]);

        // We only want to be able to train generation for the combined model.
        discriminator.trainable = false;
        const [fake, aux] = discriminator.apply(fakeTmp);
        const combined =
            tf.model({ inputs: [latent, imageClass], outputs: [fake, aux] });
        combined.compile({
            optimizer,
            loss: ['binaryCrossentropy', 'sparseCategoricalCrossentropy']
        });
        combined.summary();
        return combined;
    }


    async trainDiscriminatorOneStep(
        xTrain, yTrain, batchStart, batchSize, latentSize, generator,
        discriminator) {
        // TODO(cais): Remove tidy() once the current memory leak issue in tfjs-node
        //   and tfjs-node-gpu is fixed.
        const [x, y, auxY] = tf.tidy(() => {
            const imageBatch = xTrain.slice(batchStart, batchSize);
            const labelBatch = yTrain.slice(batchStart, batchSize).asType('float32');

            // Latent vectors.
            const zVectors = tf.randomUniform([batchSize, latentSize], -1, 1);
            const sampledLabels =
                tf.randomUniform([batchSize, 1], 0, this.numClasses, 'int32')
                    .asType('float32');

            const generatedImages =
                generator.predict([zVectors, sampledLabels], { batchSize });

            const newx = tf.concat([imageBatch, generatedImages], 0);

            const newy = tf.tidy(
                () => tf.concat(
                    [tf.ones([batchSize, 1]).mul(this.softOne), tf.zeros([batchSize, 1])]));

            const newauxY = tf.concat([labelBatch, sampledLabels], 0);
            return [newx, newy, newauxY];
        });

        const losses = await discriminator.trainOnBatch(x, [y, auxY]);
        tf.dispose([x, y, auxY]);
        return losses;
    }

    async trainCombinedModelOneStep(batchSize, latentSize, combined) {
        // TODO(cais): Remove tidy() once the current memory leak issue in tfjs-node
        //   and tfjs-node-gpu is fixed.
        const [noise, sampledLabels, trick] = tf.tidy(() => {
            // Make new latent vectors.
            const zVectors = tf.randomUniform([batchSize, latentSize], -1, 1);
            const newsampledLabels =
                tf.randomUniform([batchSize, 1], 0, this.numClasses, 'int32')
                    .asType('float32');

            // We want to train the generator to trick the discriminator.
            // For the generator, we want all the {fake, not-fake} labels to say
            // not-fake.
            const newtrick = tf.tidy(() => tf.ones([batchSize, 1]).mul(this.softOne));
            return [zVectors, newsampledLabels, newtrick];
        });

        const losses = await combined.trainOnBatch(
            [noise, sampledLabels], [trick, sampledLabels]);
        tf.dispose([noise, sampledLabels, trick]);
        return losses;
    }

    async start(): Promise<void> {
        this.mnistData = new Data();
        await this.mnistData.load();
        this.run(100, 100, 100, 0.0002, 0.5);
    }


    async run(epochs: number, batchSize: number, latentSize: number, learningRate: number, adamBeta1: number) {

        // Build the discriminator.
        const discriminator = this.buildDiscriminator();
        discriminator.compile({
            optimizer: tf.train.adam(learningRate, adamBeta1),
            loss: ['binaryCrossentropy', 'sparseCategoricalCrossentropy']
        });
        discriminator.summary();

        // Build the generator.
        const generator = this.buildGenerator(latentSize);
        generator.summary();

        const optimizer = tf.train.adam(learningRate, adamBeta1);
        const combined = this.buildCombinedModel(
            latentSize, generator, discriminator, optimizer);

        const { xs: xTrain, labels: yTrainTmp } = this.mnistData.getTrainData();
        const yTrain = tf.expandDims(yTrainTmp.argMax(-1), -1);


        let numTensors;

        const step = 0;
        for (let epoch = 0; epoch < epochs; ++epoch) {

            const tBatchBegin = tf.util.now();

            const numBatches = Math.ceil(xTrain.shape[0] / batchSize);

            for (let batch = 0; batch < numBatches; ++batch) {
                const actualBatchSize = (batch + 1) * batchSize >= xTrain.shape[0] ?
                    (xTrain.shape[0] - batch * batchSize) :
                    batchSize;

                const dLoss = await this.trainDiscriminatorOneStep(
                    xTrain, yTrain, batch * batchSize, actualBatchSize,
                    latentSize, generator, discriminator);

                // Here we use 2 * actualBatchSize here, so that we have
                // the generator optimizer over an identical number of images
                // as the discriminator.
                const gLoss = await this.trainCombinedModelOneStep(
                    2 * actualBatchSize, latentSize, combined);

                console.log(
                    `epoch ${epoch + 1}/${epochs} batch ${batch + 1}/${numBatches}: ` +
                    `dLoss = ${dLoss[0].toFixed(6)}, gLoss = ${gLoss[0].toFixed(6)}`);

            }

            console.log(
                `epoch ${epoch + 1} elapsed time: ` +
                `${((tf.util.now() - tBatchBegin) / 1e3).toFixed(1)} s`);
        }
    }
}
